---
aliases: [transformers]
---
## Content
The transformer is a [[neural network]] architecture that was initially proposed for NLP. 

The transformer was the first architecture employing only [[self-attention]] mechanisms.  
It receives and outputs variable length data vectors, which allows for different sized phrases to be receives and returned.

It is composed by two parts: an [[Transformer Encoder|(transformer) encoder]] and an [[(transformer) decoder]], which are composed by identical modules stacked together, which makes it easily scalable. 

An overview of the model is given below:


![[Pasted image 20221230002618.png|350]]




## Tags
#external 

## Source
[[Vaswani et. al (2017)]]